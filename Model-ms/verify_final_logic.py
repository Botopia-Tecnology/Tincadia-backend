import os
import sys
import numpy as np
from unittest.mock import MagicMock

# Configurar entorno para evitar logs de TF
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

def verify():
    print("--- üîç Iniciando Verificaci√≥n de L√≥gica Final ---")
    
    # 1. Mock del predictor base para no cargar el modelo real (pesado)
    mock_base = MagicMock()
    mock_base.config = {
        "classes": {
            "0": "Hola",
            "1": "Como-estas",
            "2": "Letra_P"
        }
    }
    
    # Mock de la predicci√≥n cruda
    # Simulamos una "Letra_P" con confianza baja (0.21) como en la captura del usuario
    mock_base.predict_from_coords.return_value = {
        'status': 'ok',
        'word': 'Letra_P',
        'confidence': 0.21,
        'probabilities': [0.1, 0.1, 0.21] + [0.0]*60 
    }
    
    from lsc_streaming_exacto import LSCStreamingExactoPredictor
    predictor = LSCStreamingExactoPredictor(base_predictor=mock_base)
    
    print("\n--- TEST 1: Filtro de Ruido (Confianza Baja) ---")
    # Generar 10 cuadros de "ruido"
    for _ in range(10):
        res = predictor.add_landmarks(np.zeros(226))
    
    print(f"Resultado tras ruido (0.21): {res['word']} (Deber√≠a ser None)")
    if res['word'] is None:
        print("‚úÖ [OK] Ruido filtrado correctamente.")
    else:
        print("‚ùå [FALLO] El ruido pas√≥ el filtro.")

    print("\n--- TEST 2: Control de Historial (Manual vs Autom√°tico) ---")
    # Simulamos ahora una se√±a estable pero que NO hemos aceptado todav√≠a
    mock_base.predict_from_coords.return_value = {
        'status': 'ok',
        'word': 'Hola',
        'confidence': 0.85,
        'probabilities': [0.85, 0.05, 0.1] + [0.0]*60
    }
    
    # A√±adir 5 cuadros estables de "Hola"
    for _ in range(5):
        res = predictor.add_landmarks(np.zeros(226))
        
    print(f"Palabra detectada: {res['word']}")
    print(f"Historial GPT-2: {list(predictor.word_history)} (Deber√≠a estar vac√≠o)")
    
    if len(predictor.word_history) == 0:
        print("‚úÖ [OK] El historial NO se llen√≥ autom√°ticamente. Esperando al usuario.")
    else:
        print("‚ùå [FALLO] El historial se llen√≥ solo (Spam potencial).")

    print("\n--- TEST 3: Activaci√≥n de IA tras Aceptaci√≥n ---")
    # El usuario acepta la palabra 'Hola'
    predictor.set_accepted_word("Hola")
    print(f"Historial tras aceptar: {list(predictor.word_history)}")
    
    # IMPORTANTE: Limpiar buffer para que las predicciones viejas no interfieran
    predictor.reset_buffer()
    
    # Simulamos que ahora el modelo duda entre 'Hola' y 'Como-estas'
    # Crudamente 'Como-estas' tiene 0.35 y 'Hola' tiene 0.40
    mock_base.predict_from_coords.return_value = {
        'status': 'ok',
        'word': 'Hola',
        'confidence': 0.40,
        'probabilities': [0.40, 0.35, 0.05] + [0.0]*96
    }
    
    # Forzar una "inteligencia" en el cache para 'Como-estas'
    predictor.llm_scores_cache = {1: 0.9} # 1 es 'Como-estas'
    
    # Darle 10 cuadros para que la predicci√≥n se estabilice en el buffer (necesita >= 3)
    for i in range(10):
        res = predictor.add_landmarks(np.zeros(226))
        print(f"  [Frame {i}] Status: {res['status']}, Word: {res['word']}, Conf: {res['confidence']:.2f}, Buffer: {list(predictor.prediction_buffer)}")
    
    # Debido al boost, 'Como-estas' deber√≠a ganar sobradamente
    print(f"Predicci√≥n final con IA: {res['word']}")
    if res['word'] == 'Como-estas':
         print("‚úÖ [OK] La IA impuls√≥ la palabra correcta basada en el historial.")
    else:
         print(f"‚ùå [FALLO] La IA no influy√≥. Gan√≥: {res['word']}")

    print("\n--- ‚úÖ VERIFICACI√ìN COMPLETADA ---")

if __name__ == "__main__":
    verify()
